{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controlling-diving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "innovative-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recreational-sweet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[df['TARGET'].notnull()]\n",
    "test = df[df['TARGET'].isnull()]\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driving-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train['TARGET']\n",
    "train = train.drop(columns=['TARGET'])\n",
    "test = test.drop(columns=['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ordered-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = list(train.columns)\n",
    "\n",
    "test_df = test.copy()\n",
    "train_df = train.copy()\n",
    "train_df['TARGET'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "connected-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://pranaysite.netlify.app/lightgbm/\n",
    "\n",
    "def model(features, test_features, encoding = 'ohe', n_folds = 5):\n",
    "    \n",
    "    \"\"\"Train and test a light gradient boosting model using\n",
    "    cross validation. \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        features (pd.DataFrame): \n",
    "            dataframe of training features to use \n",
    "            for training a model. Must include the TARGET column.\n",
    "        test_features (pd.DataFrame): \n",
    "            dataframe of testing features to use\n",
    "            for making predictions with the model. \n",
    "        encoding (str, default = 'ohe'): \n",
    "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n",
    "            n_folds (int, default = 5): number of folds to use for cross validation\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        submission (pd.DataFrame): \n",
    "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
    "            predicted by the model.\n",
    "        feature_importances (pd.DataFrame): \n",
    "            dataframe with the feature importances from the model.\n",
    "        valid_metrics (pd.DataFrame): \n",
    "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "    \n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "    \n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "        \n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "        \n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "    \n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "        \n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        \n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "        \n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "    \n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(n_estimators=100000, objective = 'binary', \n",
    "                                   class_weight = 'balanced', learning_rate = 0.02, \n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, \n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 100)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
    "                  early_stopping_rounds = 100, verbose = 200)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, feature_importances, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "numerous-audio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307506, 657)\n",
      "Testing Data Shape:  (48744, 657)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.837143\ttrain's binary_logloss: 0.505103\tvalid's auc: 0.792425\tvalid's binary_logloss: 0.525835\n",
      "Early stopping, best iteration is:\n",
      "[266]\ttrain's auc: 0.850235\ttrain's binary_logloss: 0.489629\tvalid's auc: 0.793625\tvalid's binary_logloss: 0.516342\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.837802\ttrain's binary_logloss: 0.504242\tvalid's auc: 0.789598\tvalid's binary_logloss: 0.524645\n",
      "Early stopping, best iteration is:\n",
      "[269]\ttrain's auc: 0.851487\ttrain's binary_logloss: 0.488168\tvalid's auc: 0.790926\tvalid's binary_logloss: 0.51456\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.836869\ttrain's binary_logloss: 0.505508\tvalid's auc: 0.800136\tvalid's binary_logloss: 0.521324\n",
      "[400]\ttrain's auc: 0.872002\ttrain's binary_logloss: 0.464401\tvalid's auc: 0.801908\tvalid's binary_logloss: 0.494633\n",
      "Early stopping, best iteration is:\n",
      "[348]\ttrain's auc: 0.864206\ttrain's binary_logloss: 0.473731\tvalid's auc: 0.80255\tvalid's binary_logloss: 0.500435\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.837737\ttrain's binary_logloss: 0.504481\tvalid's auc: 0.789618\tvalid's binary_logloss: 0.527074\n",
      "[400]\ttrain's auc: 0.873201\ttrain's binary_logloss: 0.462691\tvalid's auc: 0.791689\tvalid's binary_logloss: 0.500907\n",
      "Early stopping, best iteration is:\n",
      "[349]\ttrain's auc: 0.865208\ttrain's binary_logloss: 0.472213\tvalid's auc: 0.792137\tvalid's binary_logloss: 0.506845\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.837398\ttrain's binary_logloss: 0.504698\tvalid's auc: 0.789464\tvalid's binary_logloss: 0.526693\n",
      "[400]\ttrain's auc: 0.872639\ttrain's binary_logloss: 0.463298\tvalid's auc: 0.792429\tvalid's binary_logloss: 0.499923\n",
      "[600]\ttrain's auc: 0.898982\ttrain's binary_logloss: 0.430297\tvalid's auc: 0.792486\tvalid's binary_logloss: 0.4786\n",
      "Early stopping, best iteration is:\n",
      "[554]\ttrain's auc: 0.893389\ttrain's binary_logloss: 0.437502\tvalid's auc: 0.792978\tvalid's binary_logloss: 0.483056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.837658\ttrain's binary_logloss: 0.504584\tvalid's auc: 0.790759\tvalid's binary_logloss: 0.5253\n",
      "[400]\ttrain's auc: 0.872973\ttrain's binary_logloss: 0.46309\tvalid's auc: 0.792559\tvalid's binary_logloss: 0.4991\n",
      "Early stopping, best iteration is:\n",
      "[406]\ttrain's auc: 0.873802\ttrain's binary_logloss: 0.462016\tvalid's auc: 0.792632\tvalid's binary_logloss: 0.498386\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.837998\ttrain's binary_logloss: 0.504306\tvalid's auc: 0.791312\tvalid's binary_logloss: 0.52366\n",
      "[400]\ttrain's auc: 0.872655\ttrain's binary_logloss: 0.463383\tvalid's auc: 0.792177\tvalid's binary_logloss: 0.49835\n",
      "Early stopping, best iteration is:\n",
      "[340]\ttrain's auc: 0.863554\ttrain's binary_logloss: 0.474192\tvalid's auc: 0.792863\tvalid's binary_logloss: 0.504875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.837299\ttrain's binary_logloss: 0.505254\tvalid's auc: 0.799919\tvalid's binary_logloss: 0.526612\n",
      "Early stopping, best iteration is:\n",
      "[283]\ttrain's auc: 0.853268\ttrain's binary_logloss: 0.486416\tvalid's auc: 0.80079\tvalid's binary_logloss: 0.514593\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.837736\ttrain's binary_logloss: 0.504452\tvalid's auc: 0.792231\tvalid's binary_logloss: 0.52933\n",
      "[400]\ttrain's auc: 0.873188\ttrain's binary_logloss: 0.462877\tvalid's auc: 0.794148\tvalid's binary_logloss: 0.502845\n",
      "Early stopping, best iteration is:\n",
      "[331]\ttrain's auc: 0.862551\ttrain's binary_logloss: 0.475639\tvalid's auc: 0.794425\tvalid's binary_logloss: 0.511053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.838074\ttrain's binary_logloss: 0.504139\tvalid's auc: 0.786645\tvalid's binary_logloss: 0.52215\n",
      "[400]\ttrain's auc: 0.872787\ttrain's binary_logloss: 0.46313\tvalid's auc: 0.788306\tvalid's binary_logloss: 0.496437\n",
      "Early stopping, best iteration is:\n",
      "[336]\ttrain's auc: 0.862961\ttrain's binary_logloss: 0.474946\tvalid's auc: 0.788512\tvalid's binary_logloss: 0.503667\n",
      "LightGBM metrics\n",
      "       fold     train     valid\n",
      "0         0  0.850235  0.793625\n",
      "1         1  0.851487  0.790926\n",
      "2         2  0.864206  0.802550\n",
      "3         3  0.865208  0.792137\n",
      "4         4  0.893389  0.792978\n",
      "5         5  0.873802  0.792632\n",
      "6         6  0.863554  0.792863\n",
      "7         7  0.853268  0.800790\n",
      "8         8  0.862551  0.794425\n",
      "9         9  0.862961  0.788512\n",
      "10  overall  0.864066  0.794035\n"
     ]
    }
   ],
   "source": [
    "submission, fi, metrics = model(train_df, test_df, n_folds=10)\n",
    "print('LightGBM metrics')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recognized-lobby",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fi_sorted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-51bea0a33313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lgb_10fold.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fi_sorted' is not defined"
     ]
    }
   ],
   "source": [
    "submission.to_csv('lgb_10fold.csv', index = False)\n",
    "del submission, fi, metrics\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1.23M/1.23M [00:02<00:00, 615kB/s]\n",
      "Successfully submitted to Home Credit Default Risk"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit home-credit-default-risk -f lgb_10fold.csv -m \"Notebook Home Credit Loan | 10 Folds | LightGBM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-bible",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
